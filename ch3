#自動開啟網頁

import webbrowser

address = input('請輸入地址')
webbrowser.open('https://www.google.com.tw/maps/place/' + address)

-------------------------------------------------------------------------------
#requests使用

import requests

url = 'https://www.google.com.tw'  
response = requests.get(url)              #requests.get()之後傳回的資料型態是Response物件
print(type(response))

if response.status_code == requests.codes.ok:
    print('取得網頁成功')
    print('網址訊息 :',response.url)
    print('表頭訊息 :',response.headers)
    print('cookie訊息 :',response.cookies)
else:
    print('取得網頁內容失敗')

-------------------------------------------------------------------------------
#選取某字，計算出現的次數

import requests
import re

url = 'https://www.juksy.com/article/120091-NBA%EF%BC%8F%E5%8B%87%E5%A3%AB'
response = requests.get(url)
if response.status_code == requests.codes.ok:
    pattern = input('輸入想輸入的文字:')   

    if pattern in response.text:
        print('搜尋 %s 成功' %pattern)
    else:
        print('沒有找到 %s'%pattern)
    #計算出現次數
    name = re.findall(pattern,response.text)
    if name != None:
        print('%s 出現 %d 次'%(pattern,len(name)))
    else:
        print('%s 出現0次' %pattern)
else:
    print('網頁下載失敗')

-------------------------------------------------------------------------------------
#測試網頁下載是否成功
import requests

url = 'https//google.com.tw/Ooo'
try:
    response = requests.get(url)
    response.raise_for_status()
    print('下載成功')
except Exception as err:
    print('網頁下載失敗: %s'%err)
print('程式結束')


------------------------------------------------------------------------------------
#爬蟲程式偽裝成瀏覽器
import requests

#先在前端加入表頭(headers)內容，是字典的形式，可以偽裝成瀏覽器，按F12去Network中找，複製貼上改成字典格式即可
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)\
           AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 \
          Safari/537.36'}


url = 'https://www.kingstone.com.tw/basic/2015630743935/?zone=book&lid=home_act_prod2'
response = requests.get(url,headers=headers)
response.raise_for_status()
print('偽裝瀏覽器擷取網路資料成功')


------------------------------------------------------------------------------------
# urllib模組使用
import urllib.request

url = 'https://google.com.tw'
response = urllib.request.urlopen(url,timeout=20)    #獲取網頁HTTPResponse物件，並預設20秒，超時就跳出異常
print(type(response))
print(response)
print(response.read().decode('big5'))  #讀取物件並轉成'big5'碼

print('版本:',response.version)          #版本編號
print('網址:',response.geturl())         #物件的網址
print('下載:',response.status)           #下載狀況，如果回傳200則正常
print('表頭:')                           #取得表頭內容
for i in response.getheaders():
    print(i)
    
   
-------------------------------------------------------------------------------------
#列印所拜訪網頁的HTML文件
import urllib.request


headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)\
           AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 \
          Safari/537.36'}


url = 'https://www.kingstone.com.tw/basic/2015630743935/?zone=book&lid=home_act_prod2'
req = urllib.request.Request(url,headers=headers)
response = urllib.request.urlopen(req)
print(response.read().decode('utf-8'))

-------------------------------------------------------------------------------------
#使用urllib.request模組的urlretrieve()下載圖片
import urllib.request
url_pict = 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/29/TSMC-Logo.svg/330px-TSMC-Logo.svg.png'
fn = 'TSMC.png'
pict = urllib.request.urlretrieve(url_pict,fn)   #圖片檔將會下載到此程式碼所在的資料夾中


-------------------------------------------------------------------------------------
#URL編碼與中文編碼轉換

from urllib import parse

s = '台灣積體電路製造'
url_code = parse.quote(s)
print('URL編碼 : ',url_code)      #quote()將中文轉成URL編碼
code = parse.unquote(url_code)    #unquote()將URL編碼轉成中文
print('中文編碼 : ',code)


--------------------------------------------------------------------------------------
#URL分析拆解
from urllib import parse

url = 'https://docs.python.org/3/search.html?q=parse&check_keywords=yes&area=default'
urp = parse.urlparse(url)
print(type(urp))
print(urp)
print('scheme = ',urp.scheme)      #URL所使用的方案
print('netloc = ',urp.netloc)      #網路位置
print('path = ',urp.path)          #分層路徑 
print('params = ',urp.params)      #最後路徑元素參數
print('query = ',urp.query) 
print('fragment = ',urp.fragment)  #片段標示符號

----------------------------------------------------------------------------------------






